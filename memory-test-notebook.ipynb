{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":84493,"databundleVersionId":9871156,"sourceType":"competition"},{"sourceId":216293,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":184401,"modelId":206562},{"sourceId":227495,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":193959,"modelId":215878}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport polars as pl\nimport numpy as np\nimport os\nimport gc\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom sklearn.model_selection import KFold\n#import xgboost as xgb\n#from xgboost import XGBRegressor\nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor, log_evaluation\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import r2_score\nimport pickle\nimport time\n\ngc.enable()\n\n'''\npd.options.display.max_columns = None\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', None)\n\npl.Config.set_tbl_rows(-1)\npl.Config.set_tbl_cols(-1)\npl.Config.set_fmt_str_lengths(10000)\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:50:18.759121Z","iopub.execute_input":"2025-01-12T19:50:18.759427Z","iopub.status.idle":"2025-01-12T19:50:23.219161Z","shell.execute_reply.started":"2025-01-12T19:50:18.759401Z","shell.execute_reply":"2025-01-12T19:50:23.218351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nfrom pathlib import Path\nDATA_DIR = Path('/kaggle/input/jane-street-real-time-market-data-forecasting')\n\ndate_offset = 1500\n\nis_score_dates = 5\n\npl_all = pl.scan_parquet(DATA_DIR/\"train.parquet\").filter(pl.col(\"date_id\") >= date_offset-1).collect()\n\n# make syn_test \nsyn_test = pl_all.with_columns(\n    # pl.lit(True).alias(\"is_scored\"),\n    pl.col('date_id') - date_offset\n    ).with_row_index(name=\"row_id\", offset=0)\n\nsyn_test = syn_test.with_columns(\n    pl.when(pl.col('date_id')<is_score_dates-1).then(pl.lit(False)).otherwise(pl.lit(True)).alias(\"is_scored\")\n)\n\nsyn_test = syn_test.select(\n    ['row_id', 'date_id', 'time_id', 'symbol_id', 'weight', 'is_scored'] + [f'feature_{x:02}' for x in range(79)]\n)\n\nsyn_test_partition = syn_test.partition_by('date_id', maintain_order=True, as_dict=True)\n\noutput_dir = \"synthetic_test.parquet\"\nos.makedirs(output_dir, exist_ok=True)\n\nrow_id_offset = syn_test.filter(pl.col('date_id')<0).select('row_id').max().item()\nprint(\"row_id_offset:\", row_id_offset)\n\nfor key, _df in syn_test_partition.items():\n    if key[0] >= 0:\n        os.makedirs(f\"{output_dir}/date_id={key[0]}\", exist_ok=True)\n        _df = _df.with_columns(pl.col('row_id')-row_id_offset)\n        _df.write_parquet(f\"{output_dir}/date_id={key[0]}/part-0.parquet\")\n\n# make syn_lag\n\nsyn_lag = pl_all.select(\n    ['date_id', 'time_id', 'symbol_id'] + [f'responder_{x}' for x in range(9)]\n).with_columns(pl.col('date_id')-date_offset)\n\nsyn_lag = syn_lag.rename({f'responder_{x}': f'responder_{x}_lag_1' for x in range(9)})\n\nsyn_lag_partition = syn_lag.partition_by('date_id', maintain_order=True, as_dict=True)\n\noutput_dir = \"synthetic_lags.parquet\"\nos.makedirs(output_dir, exist_ok=True)\n\nfor key, _df in syn_lag_partition.items():\n    os.makedirs(f\"{output_dir}/date_id={key[0]+1}\", exist_ok=True)\n    _df = _df.with_columns(pl.col('date_id')+1)\n    _df.write_parquet(f\"{output_dir}/date_id={key[0]+1}/part-0.parquet\")\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:50:23.220243Z","iopub.execute_input":"2025-01-12T19:50:23.220941Z","iopub.status.idle":"2025-01-12T19:50:23.226202Z","shell.execute_reply.started":"2025-01-12T19:50:23.220917Z","shell.execute_reply":"2025-01-12T19:50:23.225359Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path = '/kaggle/input/jane-street-real-time-market-data-forecasting/'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:50:23.227830Z","iopub.execute_input":"2025-01-12T19:50:23.228057Z","iopub.status.idle":"2025-01-12T19:50:23.254637Z","shell.execute_reply.started":"2025-01-12T19:50:23.228038Z","shell.execute_reply":"2025-01-12T19:50:23.253777Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"models_path = '/kaggle/input/js_lgb_20250101_lags_as_features/other/default/1/lgb_model.pkl'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:50:23.255898Z","iopub.execute_input":"2025-01-12T19:50:23.256222Z","iopub.status.idle":"2025-01-12T19:50:23.270634Z","shell.execute_reply.started":"2025-01-12T19:50:23.256191Z","shell.execute_reply":"2025-01-12T19:50:23.269905Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(models_path, \"rb\") as f:\n    model = pickle.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:50:23.271457Z","iopub.execute_input":"2025-01-12T19:50:23.271777Z","iopub.status.idle":"2025-01-12T19:50:23.325924Z","shell.execute_reply.started":"2025-01-12T19:50:23.271747Z","shell.execute_reply":"2025-01-12T19:50:23.325197Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TimerCallback:\n    def __init__(self, max_time_seconds, loop_start_time):\n        self.max_time_seconds = max_time_seconds\n        #self.start_time = None\n        self.loop_start_time = loop_start_time\n\n    def __call__(self, env):\n        #if self.start_time is None:\n        #    self.start_time = time.time()\n\n        elapsed_time = time.time() - self.loop_start_time\n        if elapsed_time > self.max_time_seconds:\n            print(f\"Stopping training after {elapsed_time:.2f} seconds.\")\n            best_iteration = env.model.best_iteration\n            best_score = env.model.best_score\n            raise lgb.callback.EarlyStopException(best_iteration, best_score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:50:23.326444Z","iopub.execute_input":"2025-01-12T19:50:23.326656Z","iopub.status.idle":"2025-01-12T19:50:23.334197Z","shell.execute_reply.started":"2025-01-12T19:50:23.326635Z","shell.execute_reply":"2025-01-12T19:50:23.333510Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cols = [\n    'date_id', 'time_id', 'symbol_id', 'weight', 'feature_00', 'feature_01', 'feature_02', 'feature_03', 'feature_04', 'feature_05', 'feature_06', 'feature_07', 'feature_08', 'feature_09', 'feature_10',\n    'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19', 'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24',\n    'feature_25', 'feature_26', 'feature_27', 'feature_28', 'feature_29', 'feature_30', 'feature_31', 'feature_32', 'feature_33', 'feature_34', 'feature_35', 'feature_36', 'feature_37', 'feature_38',\n    'feature_39', 'feature_40', 'feature_41', 'feature_42', 'feature_43', 'feature_44', 'feature_45', 'feature_46', 'feature_47', 'feature_48', 'feature_49', 'feature_50', 'feature_51', 'feature_52',\n    'feature_53', 'feature_54', 'feature_55', 'feature_56', 'feature_57', 'feature_58', 'feature_59', 'feature_60', 'feature_61', 'feature_62', 'feature_63', 'feature_64', 'feature_65', 'feature_66',\n    'feature_67', 'feature_68', 'feature_69', 'feature_70', 'feature_71', 'feature_72', 'feature_73', 'feature_74', 'feature_75', 'feature_76', 'feature_77', 'feature_78', 'responder_6', 'responder_0_lag_1',\n    'responder_1_lag_1', 'responder_2_lag_1', 'responder_3_lag_1', 'responder_4_lag_1', 'responder_5_lag_1', 'responder_6_lag_1', 'responder_7_lag_1', 'responder_8_lag_1'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:50:23.334952Z","iopub.execute_input":"2025-01-12T19:50:23.335243Z","iopub.status.idle":"2025-01-12T19:50:23.352163Z","shell.execute_reply.started":"2025-01-12T19:50:23.335176Z","shell.execute_reply":"2025-01-12T19:50:23.351488Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_cols = [\n    'feature_00', 'feature_01', 'feature_02', 'feature_03', 'feature_04', 'feature_05', 'feature_06', 'feature_07', 'feature_08', 'feature_09', 'feature_10', 'feature_11', 'feature_12', 'feature_13',\n    'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19', 'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24', 'feature_25', 'feature_26', 'feature_27',\n    'feature_28', 'feature_29', 'feature_30', 'feature_31', 'feature_32', 'feature_33', 'feature_34', 'feature_35', 'feature_36', 'feature_37', 'feature_38', 'feature_39', 'feature_40', 'feature_41',\n    'feature_42', 'feature_43', 'feature_44', 'feature_45', 'feature_46', 'feature_47', 'feature_48', 'feature_49', 'feature_50', 'feature_51', 'feature_52', 'feature_53', 'feature_54', 'feature_55',\n    'feature_56', 'feature_57', 'feature_58', 'feature_59', 'feature_60', 'feature_61', 'feature_62', 'feature_63', 'feature_64', 'feature_65', 'feature_66', 'feature_67', 'feature_68', 'feature_69',\n    'feature_70', 'feature_71', 'feature_72', 'feature_73', 'feature_74', 'feature_75', 'feature_76', 'feature_77', 'feature_78', 'responder_0_lag_1', 'responder_1_lag_1', 'responder_2_lag_1',\n    'responder_3_lag_1', 'responder_4_lag_1', 'responder_5_lag_1', 'responder_6_lag_1', 'responder_7_lag_1', 'responder_8_lag_1'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:50:23.354214Z","iopub.execute_input":"2025-01-12T19:50:23.354446Z","iopub.status.idle":"2025-01-12T19:50:23.369867Z","shell.execute_reply.started":"2025-01-12T19:50:23.354425Z","shell.execute_reply":"2025-01-12T19:50:23.369181Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"date_id_max = pl.scan_parquet(path + 'train.parquet/').select('date_id').max().collect()['date_id'][0]\ndate_id_max","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:50:23.370962Z","iopub.execute_input":"2025-01-12T19:50:23.371342Z","iopub.status.idle":"2025-01-12T19:50:23.773858Z","shell.execute_reply.started":"2025-01-12T19:50:23.371313Z","shell.execute_reply":"2025-01-12T19:50:23.773031Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pl.scan_parquet(path + 'train.parquet/').filter(pl.col('date_id') >= date_id_max - 10).collect()\nlags_df = train_df.with_columns(pl.col('date_id') + 1).drop(['weight', 'partition_id'] + [col for col in train_df.columns if 'feature' in col]).rename({f'responder_{x}': f'responder_{x}_lag_1' for x in range(9)})\ntrain_df = train_df.drop(['responder_0', 'responder_1', 'responder_2', 'responder_3', 'responder_4', 'responder_5', 'responder_7', 'responder_8', 'partition_id']).select(pl.all().shrink_dtype())\ntrain_df = train_df.join(lags_df, on=['date_id', 'time_id', 'symbol_id'], how='left').select(pl.all().shrink_dtype()).filter(pl.col('date_id') > date_id_max - 10)\ntrain_df = train_df.with_columns(pl.col('date_id') - date_id_max - 1).with_columns([pl.col(col).cast(pl.Float32) for col in train_df.columns])\ndel lags_df\ngc.collect()\ntrain_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:50:23.774679Z","iopub.execute_input":"2025-01-12T19:50:23.775018Z","iopub.status.idle":"2025-01-12T19:50:25.176201Z","shell.execute_reply.started":"2025-01-12T19:50:23.774985Z","shell.execute_reply":"2025-01-12T19:50:25.175309Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_params = {\n    'learning_rate': 0.04588738403235412,\n    'max_depth': 12,\n    'min_data_in_leaf': 60,\n    'num_leaves': 4763,\n    'min_gain_to_split': 0.25,\n    'lambda_l1': 4.0,\n    'lambda_l2': 1786.5166849320328,\n    'feature_fraction': 0.9547872173111335\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:50:25.177048Z","iopub.execute_input":"2025-01-12T19:50:25.177283Z","iopub.status.idle":"2025-01-12T19:50:25.180944Z","shell.execute_reply.started":"2025-01-12T19:50:25.177263Z","shell.execute_reply":"2025-01-12T19:50:25.180218Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kaggle_evaluation.jane_street_inference_server","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:50:25.181662Z","iopub.execute_input":"2025-01-12T19:50:25.181982Z","iopub.status.idle":"2025-01-12T19:50:25.342595Z","shell.execute_reply.started":"2025-01-12T19:50:25.181954Z","shell.execute_reply":"2025-01-12T19:50:25.341841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lags_df : pl.DataFrame | None = None\nstreaming_data_y_list = []\nstreaming_data_X_list = []\ny_concat = None\nX_concat = None\nstreaming_data_X_concat_list = []\ntemp_i = 0\nupdated_model = None\n\n# Replace this function with your inference code.\n# You can return either a Pandas or Polars dataframe, though Polars is recommended.\n# Each batch of predictions (except the very first) must be returned within 1 minute of the batch features being provided.\ndef predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n    \"\"\"Make a prediction.\"\"\"\n    # All the responders from the previous day are passed in at time_id == 0. We save them in a global variable for access at every time_id.\n    # Use them as extra features, if you like.\n    global lags_df, streaming_data_y_list, streaming_data_X_list, temp_i, streaming_data_lags_list, y_concat, X_concat, streaming_data_X_concat_list, updated_model, train_df\n\n    if lags is not None:\n        timer_start_time = time.time()\n        lags_df = lags\n        date_id = lags_df['date_id'][0]\n    \n    test_df = test.drop(['row_id', 'is_scored'])    \n    test_df = test_df.join(lags_df, on=['date_id', 'time_id', 'symbol_id'], how='left')\n    test_df = test_df.with_columns([pl.col(col).cast(pl.Float32) for col in test_df.columns])\n    streaming_data_X_list.append(test_df)\n\n    if lags is not None:\n        y_df = lags_df.select(['date_id', 'time_id', 'symbol_id', 'responder_6_lag_1']).with_columns(pl.col('date_id') - 1).rename({'responder_6_lag_1':'responder_6'})\n        y_df = y_df.with_columns([pl.col(col).cast(pl.Float32) for col in y_df.columns])\n        streaming_data_y_list.append(y_df)\n\n        y_concat = pl.concat(streaming_data_y_list)\n        X_concat = pl.concat(streaming_data_X_list)\n        X_concat = X_concat.with_columns([pl.col(col).cast(pl.Float32) for col in X_concat.columns])\n        streaming_data_X_concat_list.append(X_concat)\n        streaming_data_X_list = []\n\n        if len(streaming_data_X_concat_list) > 2:\n            del streaming_data_X_concat_list[0], streaming_data_y_list[0]\n\n        streaming_data_X_concat_concat = pl.concat(streaming_data_X_concat_list)\n        streaming_data_X_concat_concat = streaming_data_X_concat_concat.with_columns([pl.col(col).cast(pl.Float32) for col in streaming_data_X_concat_concat.columns])\n\n        streaming_data_df = streaming_data_X_concat_concat.join(y_concat, on=['date_id', 'time_id', 'symbol_id'], how='left').drop_nulls(subset=['responder_6'])\n        streaming_data_df = streaming_data_df.with_columns([pl.col(col).cast(pl.Float32) for col in streaming_data_df.columns])\n        streaming_data_df = streaming_data_df.filter(pl.col('date_id') == date_id - 1).select(cols)\n        if streaming_data_df.shape[0] > 0:\n            train_df = pl.concat([train_df, streaming_data_df])\n\n        if train_df['date_id'].n_unique() > 1:\n            if train_df.estimated_size() / 1e9 > 25:\n                train_df_date_id_min = train_df['date_id'].min()\n                train_df = train_df.filter(pl.col('date_id') > train_df_date_id_min)\n                gc.collect()\n            streaming_data_date_id_max = train_df['date_id'].max()\n            streaming_data_val_df = train_df.filter(pl.col('date_id') == streaming_data_date_id_max)\n            streaming_data_train_df = train_df.filter(pl.col('date_id') < streaming_data_date_id_max)\n            if streaming_data_train_df.shape[0] > 1100000:\n                streaming_data_train_df = streaming_data_train_df.sample(n=1100000)\n\n            base_params = {\n                'verbosity': -1,\n                'device': 'gpu',\n                'early_stopping_round': 20,\n            }\n\n            tuned_params = {\n                'learning_rate': best_params['learning_rate'],\n                'max_depth': best_params['max_depth'],\n                'min_data_in_leaf': best_params['min_data_in_leaf'],\n                'num_leaves': best_params['num_leaves'],\n                'min_gain_to_split': best_params['min_gain_to_split'],\n                'lambda_l1': best_params['lambda_l1'],\n                'lambda_l2': best_params['lambda_l2'],\n                'feature_fraction': best_params['feature_fraction'],\n            }\n\n            updated_model = LGBMRegressor(\n                **base_params,\n                **tuned_params,\n                n_estimators=100000\n            )\n\n            X_train = streaming_data_train_df.select(feature_cols).select(pl.all().shrink_dtype()).to_pandas()\n            X_val = streaming_data_val_df.select(feature_cols).select(pl.all().shrink_dtype()).to_pandas()\n\n            y_train = streaming_data_train_df.select('responder_6').to_series().to_pandas()\n            y_val = streaming_data_val_df.select('responder_6').to_series().to_pandas()\n\n            weights_train = streaming_data_train_df.select('weight').to_series().to_pandas()\n            weights_val = streaming_data_val_df.select('weight').to_series().to_pandas()\n\n            if temp_i == 0:\n                timer_callback = TimerCallback(max_time_seconds=110, loop_start_time=timer_start_time)\n            else:\n                timer_callback = TimerCallback(max_time_seconds=58, loop_start_time=timer_start_time)\n\n            try:\n                updated_model.fit(\n                    X_train, y_train, sample_weight=weights_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_sample_weight=[weights_train, weights_val], callbacks=[timer_callback],#, log_evaluation(period=10)],\n                    init_model=model\n                )\n            except lgb.callback.EarlyStopException as e:\n                print(f\"Training stopped. Best iteration: {e.best_iteration}, Best score: {e.best_score}\")\n\n\n        temp_i += 1\n\n        gc.collect()\n\n    test_df = test_df.select(feature_cols).select(pl.all().shrink_dtype()).to_numpy()\n    \n    if updated_model == None:\n        preds = model.predict(test_df)\n    else:\n        preds = updated_model.predict(test_df)\n\n    predictions = test.select(\n        'row_id',\n        pl.lit(preds).alias('responder_6'),\n    ).select(pl.all().shrink_dtype())\n\n    if isinstance(predictions, pl.DataFrame):\n        assert predictions.columns == ['row_id', 'responder_6']\n    elif isinstance(predictions, pd.DataFrame):\n        assert (predictions.columns == ['row_id', 'responder_6']).all()\n    else:\n        raise TypeError('The predict function must return a DataFrame')\n    # Confirm has as many rows as the test data.\n    assert len(predictions) == len(test)\n\n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:50:25.343458Z","iopub.execute_input":"2025-01-12T19:50:25.343947Z","iopub.status.idle":"2025-01-12T19:50:25.360593Z","shell.execute_reply.started":"2025-01-12T19:50:25.343923Z","shell.execute_reply":"2025-01-12T19:50:25.359805Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        (\n            #'/kaggle/working/synthetic_test.parquet',\n            #'/kaggle/working/synthetic_lags.parquet',\n            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n        )\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:50:25.361454Z","iopub.execute_input":"2025-01-12T19:50:25.361771Z","iopub.status.idle":"2025-01-12T19:50:42.716652Z","shell.execute_reply.started":"2025-01-12T19:50:25.361739Z","shell.execute_reply":"2025-01-12T19:50:42.715678Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}